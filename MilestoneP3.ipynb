{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# I. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the data\n",
    "\n",
    "data_path = \"data/\"\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(data+'de_wiki_terrorism.csv', \n",
    "                   header=0, names=['Language', 'Article', 'Date', 'Pageviews'],\n",
    "                  index_col=0,\n",
    "                  verbose = True, # Verify if there are any NaNs\n",
    "                  parse_dates = [2], infer_datetime_format=True)\n",
    "\n",
    "print(\"\\nBelow the parsed data types :\\n\", data.dtypes)\n",
    "print(\"\\nData frame of dimensions\", data.shape)\n",
    "print(f\"The dataset includes {data.Article.unique().size} different articles.\")\n",
    "print('\\n', data.Article.unique(), '\\n')\n",
    "startdate, enddate = data.Date.min().date(), data.Date.max().date()\n",
    "period = 12 * (enddate.year - startdate.year) + (enddate.month - startdate.month) +1\n",
    "print(f\"The studied period starts the {startdate} to the {enddate} ({period} months).\\n\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding the index\n",
    "print(\"Are the values in the first column unique ? \", data.index.is_unique)\n",
    "print(\"If unique, indicates the first column can be used as an index.\\n\")\n",
    "\n",
    "# Sort by index to get articles per date per period\n",
    "data.sort_index(axis = 0, na_position='first', inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language column contains only one value and can be dropped.\n",
    "print(f\"Language column contains {data.Language.unique().size} value(s) : {data.Language.unique()}\")\n",
    "print(\"It can thus be removed.\\n\")\n",
    "\n",
    "data.drop(labels='Language', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Cleaning and handling missing/undefined values\n",
    "Undefined values are any non-positive numerical or non-numerical values. In case of missing values, we will discuss the possible fixes and consequently decide on our way to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## probably nothing TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Consistency in Datasets\n",
    "Here we will verify that all days were correctly retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : check that no day is missing on the period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# II. Generic Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Monthly Aggregation\n",
    "The data in our reference paper $\\text{Chilling Effects: Online Surveillance and Wikipedia Use}$ (*Jonathan W. Penney*), data is aggregated on a monthly basis and further computations are done on this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_monthly(df) :\n",
    "    \"\"\"\n",
    "    Aggregates the pageviews in a monthly fashion. Returns a DataFrame with only the numerical columns summed.\n",
    "    Note : Sets the index to date.\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    df : pd DataFrame\n",
    "        df should have at least 3 columns containing `Article`, `Date` and `Pageviews`. Column with `Date` should be named 'Date'.\n",
    "    \"\"\"\n",
    "    # Aggregate monthly\n",
    "    dataMonthly = df.set_index('Date')\n",
    "    dataMonthly = dataMonthly.resample('M').sum()\n",
    "    # Verify period\n",
    "    print(f\"The formatted dataset correctly spans from {dataMonthly.index.min().date()} to {dataMonthly.index.max().date()}.\\n\")\n",
    "    \n",
    "    return dataMonthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Mean Computation\n",
    "The first analysis technique done in the paper is a comparison of means before and after the interruption event. Let us write the methods for this purpose given a monthly pageviews dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. ITS Regression \n",
    "Following the formula of segmented regression of an interrupted time series (ITS) : \n",
    "$$\n",
    "Y_{t} = \\beta_{0}*\\text{time}+\\beta_{2}*\\text{intervention}+\\beta_{3}*\\text{postslope}+\\epsilon_{1}\n",
    "$$\n",
    "We define in the following the methods to perform such a regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "## @Gonxhe si tu peux mettre ton code c'est cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Plotting\n",
    "The reference paper uses 3 types of plots to describe the results :\n",
    "* **Histogram** of means before and after the interruption event (*cf. figure 1 in reference paper*).\n",
    "* **Segmented regression** around the interrupted event for **1 set** of articles (*cf. figure 2 in reference paper*).\n",
    "* **Segmented regression** around the interrupted event for **2 sets** of articles (*cf. figure 4A in reference paper*).\n",
    "\n",
    "Additionally, the regression plots can feature confidence intervals if prompted by the user (cf. figure 4 in reference paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO plot a histogram of means (cf. Fig 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmented_reg_1_set(df, interruption, verbose=False, ytick_step=5e5, narts=None) :\n",
    "    \"\"\"\n",
    "    Plots the ITS of a dataset of monthly Pageviews around an interruption date.\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    df : pd DataFrame\n",
    "        Pandas DataFrame containing the monthly pageviews around the interruption date.\n",
    "    interruption : string\n",
    "        Interruption date in the form of a string. Please use following fashion :\n",
    "        1st of May 1997 --> 1995-05-01\n",
    "    verbose : bool (default: False)\n",
    "        Display temp dataframes created in the process and other insightful information from the process.\n",
    "    ytick_step : int (default: 5e5)\n",
    "        Step in pageviews between 2 ticks on the y axis\n",
    "    narts : int (default: None)\n",
    "        Number of articles summed in the monthly Pageviews. Used for the legend.\n",
    "    \"\"\"\n",
    "    # Dividing dataset and excluding the revelations date\n",
    "    revelations = pd.to_datetime(interruption)\n",
    "\n",
    "    # Creating both datasets\n",
    "    pre = df.loc[df.index < revelations]\n",
    "    post = df.loc[df.index > revelations]\n",
    "    if verbose :\n",
    "        print(\"Pre-interruption pageviews:\\n\", pre.head())\n",
    "        print(\"\\nPost-interruption pageviews:\\n\", post.head())\n",
    "\n",
    "    # Verifying operation\n",
    "    if verbose : \n",
    "        print(\"Verifying coherence for split around interruption date...\")\n",
    "    assert(df.size == (pre.size + post.size))\n",
    "    if verbose :\n",
    "        print(df.size == (pre.size + post.size))\n",
    "        \n",
    "    ##########################################################\n",
    "    # Plotting\n",
    "    \n",
    "    # Create dataframe with both periods identified\n",
    "    concatenated = pd.concat([\n",
    "        pre.reset_index(drop=True).assign(period='pre'), \n",
    "        post.reset_index(drop=True).assign(period='post')], ignore_index=True)\n",
    "\n",
    "    # Creating a month-identifier column\n",
    "    concatenated = concatenated.reset_index()\n",
    "    concatenated.columns.values[0]='Months'\n",
    "    concatenated['Months'] = concatenated['Months']+1\n",
    "    # The paper shifts monthly count to start from 1.\n",
    "\n",
    "    # Identifying both periods visually\n",
    "    pal = dict(pre=\"black\", post=\"grey\")\n",
    "    g = sns.FacetGrid(concatenated, hue='period', palette=pal, height=5, aspect=1.5, xlim=(-1, 33))\n",
    "\n",
    "    #### TODO use computed regression !\n",
    "    # Creating the regressions for both periods\n",
    "    g.map(sns.regplot, \"Months\", \"Pageviews\", ci=None, robust=1, scatter=False)\n",
    "\n",
    "    # Adding the scatter data separately\n",
    "    g.map(sns.scatterplot,  \"Months\", \"Pageviews\", color=\"black\")\n",
    "\n",
    "    # Configuring the axes to fit the data\n",
    "    plt.xticks(np.arange(0, concatenated.shape[0]+2, 2), np.arange(0, concatenated.shape[0]+2, 2, dtype=int))\n",
    "    ymin, ymax = floor(concatenated['Pageviews'].min()/ytick_step)*ytick_step, floor(concatenated['Pageviews'].max()/ytick_step +1)*ytick_step\n",
    "    plt.yticks(np.arange(ymin, ymax, ytick_step), np.arange(ymin, ymax, ytick_step, dtype=int))\n",
    "\n",
    "    # Configuring the labels to be as on paper\n",
    "    plt.ylabel(\"Total Views\"+ ( '('+narts+' Wikiğedia Articles)' if narts else ''))\n",
    "    plt.xlabel(\"Time (Months)\")\n",
    "\n",
    "    # Adding grid to be as on paper\n",
    "    plt.grid(True, which='major', axis='y', alpha=0.3)\n",
    "\n",
    "    # Creating legend\n",
    "    rev_date=revelations.month_name()+' '+revelations.year\n",
    "    legend = plt.legend(labels=[\"Trend Pre-\"+rev_date, \"Trend Post-\"+rev_date, \"Total Article Views (per month)\"], \n",
    "                        bbox_to_anchor=[1,-0.1], fontsize='medium', \n",
    "                        ncol=2, borderpad=0.75, handlelength=5)\n",
    "\n",
    "    # Adding June 2013 line identifier\n",
    "    plt.text(17.5,4.2e6,'Mid '+rev_date,horizontalalignment='center')\n",
    "    plt.axvline(17.5, linewidth=2.5, color='black')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Compute plotting for 2 sets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# III. GDPR Adoption\n",
    "The European Parliament adopted the GDPR Regulation text on the $27^{th}$ of April $2016$. Our first case of interest are the following research questions at this date : \n",
    "* Is there an inverse chilling effect (e.g. immediate spike) following the announcement of the regulation adoption?\n",
    "* Has there been a change in trends in the viewing of critical terms related to the regulation after the event?\n",
    "\n",
    "We will thus answer these questions using the analysis methods from the reference paper and draw conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Monthly Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Mean Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. ITS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# GPDR Begginig of enforcement\n",
    "The GDPR regulation was applied starting from the $25^{th}$ of May $2018$ for every country of the European Union (EU) and European Economic Area (EEA). We aim to answer the following questions regarding the event : \n",
    "* Is there an inverse chilling effect (e.g. immediate spike) following the day when the regulation became effective?\n",
    "* Has there been a change in trends in the viewing of critical terms related to the regulation after the event?\n",
    "\n",
    "We will thus answer these questions using the analysis methods from the reference paper and draw conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Monthly Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Mean Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. ITS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
